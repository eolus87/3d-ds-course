{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_neural_networks__student_empty.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science for the Automotive Industry: Second practical session - DL\n",
        "\n",
        "In this session, we will dive into deep learning. We will grasp the potential of neural networks in various applications increasing the level of complexity.\n",
        "\n",
        "1. Application of NN on a linear function\n",
        "2. Application of NN on non linear functions\n",
        "3. Application of NN for image classification\n",
        "\n",
        "Developed by Nicolas Gutierrez in January 2022."
      ],
      "metadata": {
        "id": "WgM4EVa42Qio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries\n",
        "It is a good practice loading the required libraries for the code at the start of it. Additionally, doing it this way you can have some hints about what the code below will do, just by checking the types of libraries imported."
      ],
      "metadata": {
        "id": "3V8yRZzYWmMS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo8-hRs62KMW"
      },
      "outputs": [],
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "# File operations\n",
        "import glob\n",
        "import os\n",
        "# Numeric operations\n",
        "import numpy as np\n",
        "# Neural networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# Libraries for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "# Libraries for pictures\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network for linear function\n",
        "The easiest possible example of neural network is using just one layer and try to learn a linear function. We will do that step by step."
      ],
      "metadata": {
        "id": "uuoDSi3u8ybY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation of the data"
      ],
      "metadata": {
        "id": "vKj8k04g9TXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 1: Create a linear function with slope and bias (intercept)\n",
        "\n",
        "def linear_function(x):\n",
        "  # Complete the following line with a linear function of x\n",
        "  y = \n",
        "  #\n",
        "  return y"
      ],
      "metadata": {
        "id": "bN5GF15BZH9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 2: Select a training and test interval\n",
        "\n",
        "# Complete the following lines with either values or lists\n",
        "start_point_of_training = \n",
        "end_point_of_training = \n",
        "\n",
        "values_for_testing = \n",
        "#\n",
        "\n",
        "x_train = np.linspace(start_point_of_training, end_point_of_training, 256).reshape(-1, 1)\n",
        "y_train = linear_function(x_train).reshape(-1, 1)\n",
        "\n",
        "x_test = np.array(values_for_testing).reshape(-1,1)\n",
        "y_test = linear_function(x_test).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "_9WAhOfw2E_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiation of the model and definition of the NN\n",
        "In this practical session, we will make use of tensorflow and keras python packages. We will need to go through several concepts first."
      ],
      "metadata": {
        "id": "3-MmGVVW9NgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 3: Instantiate a 1 layer 1 neuron Neuran Network\n",
        "\n",
        "# Intantiate a sequential model from keras\n",
        "model = \n",
        "#\n",
        "\n",
        "# Add to the model an input layer of shape (1,) and a Dense layer with 1 neuron\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "BI0xAT2VWtF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 4: Compile the model\n",
        "\n",
        "# Compile the model using MeanAbsoluteError as loss, Adam as optimizer and \n",
        "# 'mean_squared_error', 'mean_absolute_error' as metrics\n",
        "\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "id": "b2-_-kzbdkAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting"
      ],
      "metadata": {
        "id": "zDAewbXe9bHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 5: Fit the model \n",
        "\n",
        "# Fit the model with x_train, y_train, a batch size of 8, 256 epochs, include \n",
        "# the validation data and verbose 1\n",
        "history = model.fit()\n",
        "#\n",
        "\n",
        "models = []\n",
        "histories = []\n",
        "models.append(model)\n",
        "histories.append(history)"
      ],
      "metadata": {
        "id": "bhNyBx9reSbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "133XJY7t9pAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "def plotting_models(models, histories, x_train, y_train, x_test, y_test):\n",
        "  fig, ax = plt.subplots(ncols=2, figsize=np.array([2*6.4, 4.8]))\n",
        "\n",
        "  ax[0].scatter(x_test, y_test, label='Real values', zorder=1)\n",
        "  for i in range(len(models)):\n",
        "    ax[0].scatter(x_test, models[i].predict(x_test), label= f'Predictions_{i}', zorder=2)\n",
        "  ax[0].axvline(np.min(x_train), label='Train interval_min', color='red', zorder=0)\n",
        "  ax[0].axvline(np.max(x_train), label='Train interval_max', color='green', zorder=0)\n",
        "  ax[0].set_xlabel('X values')\n",
        "  ax[0].set_ylabel('Y Values')\n",
        "  ax[0].legend()\n",
        "  #plt.xlim(right=15)\n",
        "  \n",
        "  for i in range(len(histories)):\n",
        "    ax[1].plot(histories[i].history['mean_absolute_error'], label=f'MAE_{i}')\n",
        "    ax[1].plot(histories[i].history['val_mean_absolute_error'], label=f'MAE_val_{i}')\n",
        "  ax[1].set_ylabel('Mean Absolute Error')\n",
        "  ax[1].set_xlabel('epoch')\n",
        "  ax[1].legend()"
      ],
      "metadata": {
        "id": "V2kADWuajqYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "plotting_models(models, histories, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "23WAsNBTwxxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "-RtE-hyYjr__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NN for non linear functions\n",
        "We have seen NN acting with linear functions, they can do that, but the case where they are really strong is when non linearities come into play. In this section we will tackle several examples of that"
      ],
      "metadata": {
        "id": "2wZM764Z90OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, epoch_number, model, x_train, x_test, y_test):\n",
        "        self.epoch_number = epoch_number\n",
        "        self.model = model\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.epoch_number == 0:\n",
        "          y_pred = self.model.predict(self.x_test)\n",
        "          plt.cla()\n",
        "          pl.scatter(self.x_test, self.y_test, label='Real values', color=u'#1f77b4', zorder=1)\n",
        "          pl.scatter(self.x_test, y_pred, label= 'Predictions', color= u'#ff7f0e', zorder=2)\n",
        "          pl.axvline(np.min(x_train), label='Train interval_min', color='red', zorder=0)\n",
        "          pl.axvline(np.max(x_train), label='Train interval_max', color='green', zorder=0)\n",
        "          pl.xlabel('X values')\n",
        "          pl.ylabel('Y Values')\n",
        "          pl.title(f\"Epoch {epoch}\")\n",
        "          # pl.legend()\n",
        "          display.display(pl.gcf())\n",
        "          display.clear_output(wait=True)\n",
        "          time.sleep(0.05)"
      ],
      "metadata": {
        "id": "0iGnjX4kbclk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIECEWISE"
      ],
      "metadata": {
        "id": "91qYzaYY-dAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparation of the data"
      ],
      "metadata": {
        "id": "iHdMK3fxkX_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 6: Define a piecewise function using np.piecewise\n",
        "\n",
        "def piecewise_function(x):\n",
        "  # Define a piecewise function that is continuous in the interval -10 to 10\n",
        "  y = \n",
        "  #\n",
        "  return y"
      ],
      "metadata": {
        "id": "TuktvrwI-fNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "x_tosee = np.linspace(-10, 10, 256)\n",
        "y_tosee = piecewise_function(x_tosee)\n",
        "plt.scatter(x_tosee, y_tosee)\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.title('Piecewise function')"
      ],
      "metadata": {
        "id": "pOOzrCF7g9wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "x_train = np.linspace(-10, 10, 256).reshape(-1, 1)\n",
        "y_train = piecewise_function(x_train).reshape(-1, 1)\n",
        "\n",
        "x_test = np.linspace(-50, 50, 256).reshape(-1,1)\n",
        "y_test = piecewise_function(x_test).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "EwqymU2IAdbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting"
      ],
      "metadata": {
        "id": "sfUgwuBTAeNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 7: Complete the following function\n",
        "\n",
        "def compile_and_fit_nonlinear(neurons, epochs, lr, bs, x_train, y_train, x_test, y_test, minval, maxval):\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  # Instantiate a sequential model and add an input layer of shape (1,)\n",
        "  model = \n",
        "\n",
        "  #\n",
        "  for i in range(len(neurons)):\n",
        "    initializer = tf.keras.initializers.RandomUniform(minval=minval, \n",
        "                                                      maxval=maxval, \n",
        "                                                      seed=1)\n",
        "    # Add a Dense layer to the model with \"relu\" activation, \n",
        "    # kernel_initializer = initializer and bias_initializer as Ones. The number\n",
        "    # of neurons will be neurons[i]\n",
        "    model.add()\n",
        "    #\n",
        "  \n",
        "  # Add a Dense layer to the model with one neuron\n",
        "  \n",
        "  #\n",
        "\n",
        "  # Compile the model using MeanSquaredError as loss, Adam with learning_rate = lr \n",
        "  # as optimizer and 'mean_squared_error', 'mean_absolute_error' as metrics\n",
        "  \n",
        "  #\n",
        "  \n",
        "  # Fit the model using the following options batch size = bs, epochs=epochs, True for shuffle,\n",
        "  # use training data and validation data. use as a callback the class defined\n",
        "  # previously with inputs (100, model, x_train, x_test, y_test)\n",
        "  history = \n",
        "  #\n",
        "\n",
        "  model.summary()\n",
        "  for i in range(len(model.layers)):\n",
        "    print(f\"Layer: {i}\")\n",
        "    print(model.layers[i].weights[0].numpy())\n",
        "    print(model.layers[i].bias.numpy())\n",
        "  return model, history"
      ],
      "metadata": {
        "id": "EMPgh0PK2TQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 8: Play with the values in this cell to see how they affect the results\n",
        "\n",
        "models = []\n",
        "histories = []\n",
        "model, history = compile_and_fit_nonlinear([2], 4000, 0.005, 128, x_train, y_train, x_test, y_test, -0.1, 0.1)\n",
        "models.append(model)\n",
        "histories.append(history)\n",
        "\n",
        "# test_scores = model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "jQqmzE3mAfyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model, history = compile_and_fit_1layer_nonlinear([2], 4000, 0.005, 128, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "UuWVt_cuyNAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "e3H4rUKCArid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "plotting_models(models, histories, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "TMGzB5kzUvSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRIGONOMETRIC"
      ],
      "metadata": {
        "id": "dKmn3rQVlUWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparation of the data"
      ],
      "metadata": {
        "id": "rDlbYAcwlYXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 9: Define e trigonometric function of x using numpy\n",
        "\n",
        "def trigonometric(x):\n",
        "  # Use numpy to define a trigonometric function of x\n",
        "  y = \n",
        "  #\n",
        "  return y"
      ],
      "metadata": {
        "id": "PJwA1rXIldVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "# Plot to doublecheck\n",
        "x_tosee = np.linspace(0, 2*np.pi, 256)\n",
        "y_tosee = trigonometric(x_tosee)\n",
        "plt.scatter(x_tosee, y_tosee)\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.title('Trigonometric function')"
      ],
      "metadata": {
        "id": "fz3V67Y5kMx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "x_train = np.linspace(0, 2*np.pi, 256).reshape(-1, 1)\n",
        "y_train = trigonometric(x_train).reshape(-1, 1)\n",
        "\n",
        "x_test = np.linspace(-3*np.pi, 3*np.pi, 512).reshape(-1,1)\n",
        "y_test = trigonometric(x_test).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "d6waeFyznjkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting"
      ],
      "metadata": {
        "id": "Chn8yQKBlcrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 10: Use the function compile_and_fit_non_linear\n",
        "\n",
        "models = []\n",
        "histories = []\n",
        "\n",
        "# Use the suggested function with at least three layers with less than 10 neurons\n",
        "# thousands of epochs, lr 0.005 and bs multiple of 2 up to 256, minval -0.5 y maxval 0.5\n",
        "model, history = \n",
        "#\n",
        "\n",
        "models.append(model)\n",
        "histories.append(history)\n",
        "\n",
        "# test_scores = model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "h8l4atlDnOCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "imrIMa55lfsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "plotting_models(models, histories, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "aLad3LUWsjVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NN for classification\n",
        "The first exercise we will do here is developing a NN as a classifier between cars and non cars pictures. For that, we will have available a subset of pictures from the following references:\n",
        "\n",
        "- [Car or Not a Car](https://medium.com/@oviyum/lessons-from-fine-tuning-a-convolutional-binary-classifier-ccf9388e46d8)\n",
        "- [Cars Dataset](https://ai.stanford.edu/~jkrause/cars/car_dataset.html)\n",
        "- [Caltech256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)"
      ],
      "metadata": {
        "id": "ZF2S29vhs2xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation of the data"
      ],
      "metadata": {
        "id": "MA-_viUS4WTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "# Properties of the model\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "1FK6C6MwZZkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "# You will receive a prompt asking for permissions to access your google drive \n",
        "# from google collab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Qa5q07Y0s52I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 11: Look for the cars and non cars folder\n",
        "\n",
        "# Look for the following folders in your google drive\n",
        "cars_training_folder = ''\n",
        "cars_test_folder = ''\n",
        "noncars_train_folder = ''\n",
        "noncars_test_folder = ''\n",
        "#\n",
        "\n",
        "list_of_files = glob.glob(cars_training_folder)\n",
        "print(\"\\nCar training folder:\")\n",
        "print(list_of_files[:2])\n",
        "\n",
        "list_of_files = glob.glob(cars_test_folder)\n",
        "print(\"\\nCar training folder:\")\n",
        "print(list_of_files[:2])\n",
        "\n",
        "list_of_files = glob.glob(noncars_train_folder)\n",
        "print(\"\\nCar training folder:\")\n",
        "print(list_of_files[:2])\n",
        "\n",
        "list_of_files = glob.glob(noncars_test_folder)\n",
        "print(\"\\nCar training folder:\")\n",
        "print(list_of_files[:2])"
      ],
      "metadata": {
        "id": "hovbkQi9IEhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "def show_example(folder_path):\n",
        "  list_of_pictures = glob.glob(folder_path + \"*.jpg\")\n",
        "  number_of_pictures = len(list_of_pictures)\n",
        "  random_picture = list_of_pictures[np.random.randint(0, high=number_of_pictures-1)]\n",
        "  print(f\"Example file: {random_picture}\")\n",
        "  print(f\"Number of jpg files: {number_of_pictures}\")\n",
        "  return str(random_picture)"
      ],
      "metadata": {
        "id": "3syfK7CK02f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 12: Use the function show_example to verify you have selected the folders correctly\n",
        "\n",
        "# Include your line here\n",
        "random_picture = \n",
        "#\n",
        "\n",
        "PIL.Image.open(random_picture)"
      ],
      "metadata": {
        "id": "szHScSLg1fgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 13: Look for the correct folders to use image_dataset_from_directory from keras\n",
        "\n",
        "# Complete the path as a string below\n",
        "data_dir_train = ''\n",
        "#\n",
        "# Train dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  label_mode='binary')\n",
        "\n",
        "# Complete the path as a string below\n",
        "data_dir_test = ''\n",
        "#\n",
        "# Test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir_test,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  label_mode='binary')\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(f\"Training classes: {class_names}\")\n",
        "\n",
        "class_names = test_ds.class_names\n",
        "print(f\"Test classes: {class_names}\")\n",
        "\n",
        "# for image_batch, labels_batch in train_ds:\n",
        "#   print(f\"Shape of the pictures in the batch: {image_batch.shape}\")\n",
        "#   print(f\"Shape of the labels in the batch: {labels_batch.shape}\")\n",
        "#   break\n",
        "\n",
        "# The output of this cell should be:\n",
        "# Found 1000 files belonging to 2 classes.\n",
        "# Found 300 files belonging to 2 classes.\n",
        "# Training classes: ['cars', 'others']\n",
        "# Test classes: ['cars', 'others']\n",
        "# Shape of the pictures in the batch: (256, 128, 128, 3)\n",
        "# Shape of the labels in the batch: (256, 1)"
      ],
      "metadata": {
        "id": "nAf0v-o54PNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "# Extra check, if you run this cell you will a 3 by 3 set of pictures with the corresponding labels\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[int(labels[i])])\n",
        "    plt.axis(\"off\")\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "1cyX31Lg5wWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting with convolutions"
      ],
      "metadata": {
        "id": "AX1rh0kfNjo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 14: Complete the following function to instantiate, compile and fit a convolutional neural network\n",
        "\n",
        "def compile_and_fit_conv(convfilters, convsize, densesize, lr, epochs, train_ds, val_ds):\n",
        "  # Sanity checks\n",
        "  if len(convfilters) != len(convsize):\n",
        "    raise IndexError('Length of convfilters and convsize is required to be the same.')\n",
        "  if len(convfilters) < 1 or len(convsize) < 1:\n",
        "    raise IndexError('Length of convfilters or convsize is required to be higher than 0.')\n",
        "  if len(densesize) < 1:\n",
        "    raise IndexError('Length of densesize is required to be higher than 0.')\n",
        "\n",
        "  # Gettting some handy variables\n",
        "  class_names = train_ds.class_names\n",
        "  num_classes = len(class_names)\n",
        "\n",
        "  # Cleaning keras backend to avoid piling up training phases\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  # Definition of the model\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
        "  for i in range(len(convfilters)):\n",
        "    initializer = tf.keras.initializers.HeNormal(seed=1)\n",
        "    # Add to the model a suitable convolutional layer, use padding 'same' and activation 'relu'\n",
        "    ,\n",
        "    #\n",
        "    # Add to the model a suitable max pooling layer\n",
        "    ,\n",
        "    #\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  for j in range(len(densesize)):\n",
        "    # Add to the model a Dense layer, use activation \"relu\" and initializer as a kernel initializer\n",
        " \n",
        "    #\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Copile the model using a loss function as binary crossentropy (logits=False),\n",
        "  # Adam with lr as learning rate and accuracy as metrics\n",
        "\n",
        "  #\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  # Fit the model\n",
        "  history = \n",
        "  #\n",
        "  \n",
        "  return model, history"
      ],
      "metadata": {
        "id": "Zr5oIbsJ6TVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 15: Select suitable parameters for compile and fit function\n",
        "\n",
        "# Do not modify the format of the variables\n",
        "convfilters = []\n",
        "convsize = []\n",
        "densesize = []\n",
        "lr =  # Careful with this value, around 0.01 should be fine\n",
        "epochs =  # Around 20 should be fine\n",
        "#\n",
        "\n",
        "model, history = compile_and_fit_conv(convfilters, convsize, densesize, lr, epochs, train_ds, test_ds)"
      ],
      "metadata": {
        "id": "lh2GtptV_RC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation with convolutions"
      ],
      "metadata": {
        "id": "qLeupmW6Nyxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "def plotting_prediction(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  \n",
        "  fig, ax = plt.subplots(ncols=2, figsize=np.array([2*6.4, 4.8]))\n",
        "\n",
        "  ax[0].plot(np.arange(1,len(acc)+1), acc, label='Training Accuracy')\n",
        "  ax[0].plot(np.arange(1,len(acc)+1), val_acc, label='Validation Accuracy')\n",
        "  ax[0].legend()\n",
        "  ax[0].set_title('Training and Validation Accuracy')\n",
        "  ax[0].set_xlabel('Epochs')\n",
        "  ax[0].set_ylabel('Accuracy')\n",
        "  \n",
        "  ax[1].plot(np.arange(1,len(loss)+1), loss, label='Training Loss')\n",
        "  ax[1].plot(np.arange(1,len(loss)+1), val_loss, label='Validation Loss')\n",
        "  ax[1].legend()\n",
        "  ax[1].set_title('Training and Validation Loss')\n",
        "  ax[1].set_xlabel('Epochs')\n",
        "  ax[1].set_ylabel('Loss')"
      ],
      "metadata": {
        "id": "YbW0ND8dN1Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "plotting_prediction(history)"
      ],
      "metadata": {
        "id": "C0pwbDOsO6Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 16: Locate the training pictures\n",
        "\n",
        "# Modify the following line\n",
        "test_pictures_path = ''\n",
        "#\n",
        "\n",
        "sample_pictures = glob.glob(test_pictures_path)\n",
        "print(sample_pictures)\n",
        "\n",
        "# The output of this cell should be\n",
        "# ['/content/drive/MyDrive/nebrija_data_science_student/02-neural_networks/datasets/test_01.jpg', \n",
        "# '/content/drive/MyDrive/nebrija_data_science_student/02-neural_networks/datasets/test_02.jpg', \n",
        "# '/content/drive/MyDrive/nebrija_data_science_student/02-neural_networks/datasets/test_03.jpg']"
      ],
      "metadata": {
        "id": "wIFsLMed_hLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "def test_other_pictures(list_of_pictures):\n",
        "  for i in range(len(list_of_pictures)):\n",
        "    print(f\"Picture number {i}: {os.path.basename(list_of_pictures[i])}\")\n",
        "    test_picture = np.array(PIL.Image.open(list_of_pictures[i]))\n",
        "    print(f\"Picture size {test_picture.shape}\")\n",
        "    test_picture_resized = tf.expand_dims(tf.image.resize(test_picture, (img_height, img_width)),0)\n",
        "    print(f\"Piture size after resize {test_picture_resized.shape}\")\n",
        "    prediction = model.predict(test_picture_resized)\n",
        "    if prediction > 0.5: \n",
        "      prediction_class = 1\n",
        "    else:\n",
        "      prediction_class = 0\n",
        "    print(f\"Model prediction: {prediction} - {class_names[prediction_class]}\\n\")"
      ],
      "metadata": {
        "id": "FF7aQjVfGNA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "test_other_pictures(sample_pictures)"
      ],
      "metadata": {
        "id": "XTB8nqXhGn3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 17: Store the model in your google drive for later use\n",
        "\n",
        "# Modify the following line to include the corresponding method\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "6Mylk-DSGt0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 18: Load the model and check the results are the same\n",
        "\n",
        "# Delete the model first\n",
        "\n",
        "#\n",
        "\n",
        "# Then load it as 'model' from the file you have created previously\n",
        "model = \n",
        "#"
      ],
      "metadata": {
        "id": "S-F3vsfEV3SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Do not modify this cell, not an exercise\n",
        "\n",
        "test_other_pictures(sample_pictures)"
      ],
      "metadata": {
        "id": "wC9yCbx8WAcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}